{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "import nltk\n",
    "from random import shuffle\n",
    "import random\n",
    "random.seed(3)\n",
    "\n",
    "from nltk.corpus import senseval\n",
    "instances = list(senseval.instances('hard.pos'))\n",
    "shuffle(instances)\n",
    "size = int(len(instances) * 0.1)\n",
    "train_set, test_set = instances[size:], instances[:size]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "SensevalInstance(word='hard-a', position=19, context=[('david', 'NNP'), ('ogden', 'NNP'), ('stiers', 'NNP'), ('makes', 'VBZ'), ('a', 'DT'), ('valiant', 'JJ'), ('effort', 'NN'), ('to', 'TO'), ('bring', 'VB'), ('the', 'DT'), ('town', 'NN'), (\"'s\", 'POS'), ('mayor', 'NN'), ('to', 'TO'), ('life', 'NN'), (',', ','), ('but', 'CC'), ('often', 'RB'), ('is', 'VBZ'), ('hard', 'JJ'), ('to', 'TO'), ('decipher', 'VB'), ('because', 'IN'), ('of', 'IN'), ('an', 'DT'), ('aggressive', 'JJ'), ('southern', 'NNP'), ('accent', 'NN'), ('and', 'CC'), ('blustery', 'JJ'), ('tone', 'NN'), ('.', '.')], senses=('HARD1',))"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_set[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def sense_features(sense_eval_inst):\n",
    "    feature_dict={}\n",
    "    position=sense_eval_inst.position\n",
    "    feature_dict[\"position\"]=position\n",
    "    return feature_dict\n",
    "    \n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'position': 19}"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sense_features(train_set[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'HARD1'"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_set[0].senses[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "train_feature_set=[(sense_features(item),item.senses[0]) for item in train_set]\n",
    "test_feature_set=[(sense_features(item),item.senses[0]) for item in test_set]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "({'position': 3}, 'HARD1')\n",
      "({'position': 9}, 'HARD1')\n",
      "({'position': 18}, 'HARD1')\n",
      "({'position': 2}, 'HARD1')\n",
      "({'position': 14}, 'HARD1')\n"
     ]
    }
   ],
   "source": [
    "for item in train_feature_set[:5]:\n",
    "    print(item)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "({'position': 24}, 'HARD1')\n",
      "({'position': 14}, 'HARD1')\n",
      "({'position': 3}, 'HARD1')\n",
      "({'position': 3}, 'HARD1')\n",
      "({'position': 5}, 'HARD3')\n"
     ]
    }
   ],
   "source": [
    "for item in train_feature_set[-5:]:\n",
    "    print(item)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "({'position': 20}, 'HARD1')"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_feature_set[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "classifier = nltk.NaiveBayesClassifier.train(train_feature_set)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.8267898383371824\n"
     ]
    }
   ],
   "source": [
    "print(nltk.classify.accuracy(classifier, test_feature_set))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[({'position': 20}, 'HARD1'),\n",
       " ({'position': 10}, 'HARD1'),\n",
       " ({'position': 3}, 'HARD1'),\n",
       " ({'position': 15}, 'HARD1'),\n",
       " ({'position': 66}, 'HARD1')]"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_feature_set[:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[({'position': 19}, 'HARD1'),\n",
       " ({'position': 5}, 'HARD1'),\n",
       " ({'position': 15}, 'HARD1'),\n",
       " ({'position': 3}, 'HARD1'),\n",
       " ({'position': 3}, 'HARD1')]"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_feature_set[:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'HARD1'"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "classifier.classify(sense_features(test_set[0]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'HARD1'"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "classifier.classify(sense_features(test_set[-5]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[({'position': 3}, 'HARD1'),\n",
       " ({'position': 4}, 'HARD1'),\n",
       " ({'position': 18}, 'HARD1'),\n",
       " ({'position': 14}, 'HARD1'),\n",
       " ({'position': 19}, 'HARD1')]"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_feature_set[-5:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "('HARD1',)\n",
      "('HARD1',)\n"
     ]
    }
   ],
   "source": [
    "for t in test_set[:2]:\n",
    "    print(t.senses)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'position': 15, 'prev_tag': 'IN', 'prev_word': 'with'}"
      ]
     },
     "execution_count": 54,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def sense_features(sense_eval_inst):\n",
    "    feature_dict={}\n",
    "    position=sense_eval_inst.position\n",
    "    context=sense_eval_inst.context\n",
    "    cur_word_tag=context[position]\n",
    "    prev_word_tag=context[position-1]\n",
    "    #print(\"current\", position,cur_word_tag)\n",
    "    #print(\"previous\", prev_word_tag)    \n",
    "    feature_dict[\"position\"]=position\n",
    "    feature_dict[\"prev_word\"]=prev_word_tag[0]\n",
    "    feature_dict[\"prev_tag\"]=prev_word_tag[1]\n",
    "    return feature_dict\n",
    "sense_features(train_set[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "train_feature_set=[(sense_features(item),item.senses[0]) for item in train_set]\n",
    "test_feature_set=[(sense_features(item),item.senses[0]) for item in test_set]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "({'position': 15, 'prev_word': 'with', 'prev_tag': 'IN'}, 'HARD1')\n",
      "({'position': 8, 'prev_word': 'really', 'prev_tag': 'RB'}, 'HARD1')\n",
      "({'position': 44, 'prev_word': 'little', 'prev_tag': 'JJ'}, 'HARD1')\n",
      "({'position': 5, 'prev_word': 'a', 'prev_tag': 'DT'}, 'HARD1')\n",
      "({'position': 6, 'prev_word': 'it', 'prev_tag': 'PRP'}, 'HARD1')\n"
     ]
    }
   ],
   "source": [
    "for a in train_feature_set[:5]:\n",
    "    print(a)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "classifier1 = nltk.NaiveBayesClassifier.train(train_feature_set)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.8267898383371824\n"
     ]
    }
   ],
   "source": [
    "print(nltk.classify.accuracy(classifier, test_feature_set))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.812933025404157\n"
     ]
    }
   ],
   "source": [
    "print(nltk.classify.accuracy(classifier1, test_feature_set))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'next_tag': 'JJ',\n",
       " 'next_word': 'economic',\n",
       " 'position': 15,\n",
       " 'prev_tag': 'IN',\n",
       " 'prev_word': 'with'}"
      ]
     },
     "execution_count": 63,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def sense_features(sense_eval_inst):\n",
    "    feature_dict={}\n",
    "    position=sense_eval_inst.position\n",
    "    context=sense_eval_inst.context\n",
    "    cur_word_tag=context[position]\n",
    "    prev_word_tag=context[position-1]\n",
    "    next_word,next_tag=\"\",\"\"\n",
    "    if position<len(context)-1:\n",
    "        next_word_tag=context[position+1]\n",
    "        if len(next_word_tag)==2: next_word,next_tag=next_word_tag\n",
    "    feature_dict[\"position\"]=position\n",
    "    feature_dict[\"prev_word\"]=prev_word_tag[0]\n",
    "    feature_dict[\"prev_tag\"]=prev_word_tag[1]\n",
    "    feature_dict[\"next_word\"]=next_word\n",
    "    feature_dict[\"next_tag\"]=next_tag\n",
    "\n",
    "    return feature_dict\n",
    "sense_features(train_set[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_feature_set=[(sense_features(item),item.senses[0]) for item in train_set]\n",
    "test_feature_set=[(sense_features(item),item.senses[0]) for item in test_set]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "classifier2 = nltk.NaiveBayesClassifier.train(train_feature_set)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.8429561200923787\n"
     ]
    }
   ],
   "source": [
    "print(nltk.classify.accuracy(classifier2, test_feature_set))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "word_2,tag_2=\"\",\"\"\n",
    "context=train_set[0].context\n",
    "position=train_set[0].position\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 ('tough', 'NNP') -15\n",
      "1 ('times', 'NNP') -14\n",
      "2 (';', ':') -13\n",
      "3 ('the', 'DT') -12\n",
      "4 ('mercer', 'NNP') -11\n",
      "5 ('survey', 'NN') -10\n",
      "6 ('reveals', 'VBZ') -9\n",
      "7 ('some', 'DT') -8\n",
      "8 ('steps', 'NNS') -7\n",
      "9 ('companies', 'NNS') -6\n",
      "10 ('are', 'VBP') -5\n",
      "11 ('taking', 'VBG') -4\n",
      "12 ('to', 'TO') -3\n",
      "13 ('deal', 'VB') -2\n",
      "14 ('with', 'IN') -1\n",
      "15 ('harder', 'JJ') 0\n",
      "16 ('economic', 'JJ') 1\n",
      "17 ('times', 'NNS') 2\n",
      "18 ('.', '.') 3\n"
     ]
    }
   ],
   "source": [
    "\n",
    "for index,word_tag in enumerate(context):\n",
    "    print(index, word_tag, index-position)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{('tag', -15): 'NNP',\n",
       " ('tag', -14): 'NNP',\n",
       " ('tag', -13): ':',\n",
       " ('tag', -12): 'DT',\n",
       " ('tag', -11): 'NNP',\n",
       " ('tag', -10): 'NN',\n",
       " ('tag', -9): 'VBZ',\n",
       " ('tag', -8): 'DT',\n",
       " ('tag', -7): 'NNS',\n",
       " ('tag', -6): 'NNS',\n",
       " ('tag', -5): 'VBP',\n",
       " ('tag', -4): 'VBG',\n",
       " ('tag', -3): 'TO',\n",
       " ('tag', -2): 'VB',\n",
       " ('tag', -1): 'IN',\n",
       " ('tag', 0): 'JJ',\n",
       " ('tag', 1): 'JJ',\n",
       " ('tag', 2): 'NNS',\n",
       " ('tag', 3): '.',\n",
       " ('word', -15): 'tough',\n",
       " ('word', -14): 'times',\n",
       " ('word', -13): ';',\n",
       " ('word', -12): 'the',\n",
       " ('word', -11): 'mercer',\n",
       " ('word', -10): 'survey',\n",
       " ('word', -9): 'reveals',\n",
       " ('word', -8): 'some',\n",
       " ('word', -7): 'steps',\n",
       " ('word', -6): 'companies',\n",
       " ('word', -5): 'are',\n",
       " ('word', -4): 'taking',\n",
       " ('word', -3): 'to',\n",
       " ('word', -2): 'deal',\n",
       " ('word', -1): 'with',\n",
       " ('word', 0): 'harder',\n",
       " ('word', 1): 'economic',\n",
       " ('word', 2): 'times',\n",
       " ('word', 3): '.'}"
      ]
     },
     "execution_count": 75,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def sense_features(sense_eval_inst):\n",
    "    feature_dict={}\n",
    "    position=sense_eval_inst.position\n",
    "    context=sense_eval_inst.context\n",
    "    for index,word_tag in enumerate(context):\n",
    "        offset=index-position\n",
    "        if len(word_tag)!=2: continue\n",
    "        word,tag=word_tag\n",
    "        #print(word,tag,offset)\n",
    "        feature_dict[(\"word\",offset)]=word\n",
    "        feature_dict[(\"tag\",offset)]=tag\n",
    "    return feature_dict\n",
    "\n",
    "sense_features(train_set[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "train_feature_set=[(sense_features(item),item.senses[0]) for item in train_set]\n",
    "test_feature_set=[(sense_features(item),item.senses[0]) for item in test_set]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "classifier3 = nltk.NaiveBayesClassifier.train(train_feature_set)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.6674364896073903\n"
     ]
    }
   ],
   "source": [
    "print(nltk.classify.accuracy(classifier3, test_feature_set))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def gender_features(word):\n",
    "    return {'last_letter': word[-1]}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from nltk.corpus import names\n",
    "labeled_names = ([(name, 'male') for name in names.words('male.txt')] +\n",
    "[(name, 'female') for name in names.words('female.txt')])\n",
    "import random\n",
    "random.shuffle(labeled_names)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.796\n"
     ]
    }
   ],
   "source": [
    "featuresets = [(gender_features(n), gender) for (n, gender) in labeled_names]\n",
    "train_set, test_set = featuresets[500:], featuresets[:500]\n",
    "nb_classifier = nltk.NaiveBayesClassifier.train(train_set)\n",
    "print(nltk.classify.accuracy(nb_classifier, test_set))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.796\n"
     ]
    }
   ],
   "source": [
    "dt_classifier = nltk.DecisionTreeClassifier.train(train_set)\n",
    "print(nltk.classify.accuracy(dt_classifier, test_set))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  ==> Training (100 iterations)\n",
      "\n",
      "      Iteration    Log Likelihood    Accuracy\n",
      "      ---------------------------------------\n",
      "             1          -0.69315        0.372\n",
      "             2          -0.37566        0.761\n",
      "             3          -0.37524        0.761\n",
      "             4          -0.37498        0.761\n",
      "             5          -0.37481        0.761\n",
      "             6          -0.37469        0.761\n",
      "             7          -0.37460        0.761\n",
      "             8          -0.37453        0.761\n",
      "             9          -0.37448        0.761\n",
      "            10          -0.37443        0.761\n",
      "            11          -0.37439        0.761\n",
      "            12          -0.37436        0.761\n",
      "            13          -0.37433        0.761\n",
      "            14          -0.37431        0.761\n",
      "            15          -0.37429        0.761\n",
      "            16          -0.37427        0.761\n",
      "            17          -0.37425        0.761\n",
      "            18          -0.37424        0.761\n",
      "            19          -0.37422        0.761\n",
      "            20          -0.37421        0.761\n",
      "            21          -0.37420        0.761\n",
      "            22          -0.37419        0.761\n",
      "            23          -0.37418        0.761\n",
      "            24          -0.37417        0.761\n",
      "            25          -0.37416        0.761\n",
      "            26          -0.37416        0.761\n",
      "            27          -0.37415        0.761\n",
      "            28          -0.37414        0.761\n",
      "            29          -0.37414        0.761\n",
      "            30          -0.37413        0.761\n",
      "            31          -0.37413        0.761\n",
      "            32          -0.37412        0.761\n",
      "            33          -0.37412        0.761\n",
      "            34          -0.37411        0.761\n",
      "            35          -0.37411        0.761\n",
      "            36          -0.37411        0.761\n",
      "            37          -0.37410        0.761\n",
      "            38          -0.37410        0.761\n",
      "            39          -0.37410        0.761\n",
      "            40          -0.37409        0.761\n",
      "            41          -0.37409        0.761\n",
      "            42          -0.37409        0.761\n",
      "            43          -0.37408        0.761\n",
      "            44          -0.37408        0.761\n",
      "            45          -0.37408        0.761\n",
      "            46          -0.37408        0.761\n",
      "            47          -0.37407        0.761\n",
      "            48          -0.37407        0.761\n",
      "            49          -0.37407        0.761\n",
      "            50          -0.37407        0.761\n",
      "            51          -0.37407        0.761\n",
      "            52          -0.37406        0.761\n",
      "            53          -0.37406        0.761\n",
      "            54          -0.37406        0.761\n",
      "            55          -0.37406        0.761\n",
      "            56          -0.37406        0.761\n",
      "            57          -0.37406        0.761\n",
      "            58          -0.37405        0.761\n",
      "            59          -0.37405        0.761\n",
      "            60          -0.37405        0.761\n",
      "            61          -0.37405        0.761\n",
      "            62          -0.37405        0.761\n",
      "            63          -0.37405        0.761\n",
      "            64          -0.37405        0.761\n",
      "            65          -0.37405        0.761\n",
      "            66          -0.37404        0.761\n",
      "            67          -0.37404        0.761\n",
      "            68          -0.37404        0.761\n",
      "            69          -0.37404        0.761\n",
      "            70          -0.37404        0.761\n",
      "            71          -0.37404        0.761\n",
      "            72          -0.37404        0.761\n",
      "            73          -0.37404        0.761\n",
      "            74          -0.37404        0.761\n",
      "            75          -0.37404        0.761\n",
      "            76          -0.37403        0.761\n",
      "            77          -0.37403        0.761\n",
      "            78          -0.37403        0.761\n",
      "            79          -0.37403        0.761\n",
      "            80          -0.37403        0.761\n",
      "            81          -0.37403        0.761\n",
      "            82          -0.37403        0.761\n",
      "            83          -0.37403        0.761\n",
      "            84          -0.37403        0.761\n",
      "            85          -0.37403        0.761\n",
      "            86          -0.37403        0.761\n",
      "            87          -0.37403        0.761\n",
      "            88          -0.37403        0.761\n",
      "            89          -0.37402        0.761\n",
      "            90          -0.37402        0.761\n",
      "            91          -0.37402        0.761\n",
      "            92          -0.37402        0.761\n",
      "            93          -0.37402        0.761\n",
      "            94          -0.37402        0.761\n",
      "            95          -0.37402        0.761\n",
      "            96          -0.37402        0.761\n",
      "            97          -0.37402        0.761\n",
      "            98          -0.37402        0.761\n",
      "            99          -0.37402        0.761\n",
      "         Final          -0.37402        0.761\n"
     ]
    }
   ],
   "source": [
    "ment_classifier = nltk.MaxentClassifier.train(train_set)\n",
    "#nltk.classify.maxent"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.796\n"
     ]
    }
   ],
   "source": [
    "print(nltk.classify.accuracy(ment_classifier, test_set))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'next_tag': 'WDT',\n",
       " 'next_word': 'that',\n",
       " 'position': 13,\n",
       " 'prev_tag': 'WRB',\n",
       " 'prev_word': 'how'}"
      ]
     },
     "execution_count": 90,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from nltk.corpus import senseval\n",
    "instances = list(senseval.instances('hard.pos'))\n",
    "shuffle(instances)\n",
    "size = int(len(instances) * 0.1)\n",
    "train_set, test_set = instances[size:], instances[:size]\n",
    "\n",
    "def sense_features(sense_eval_inst):\n",
    "    feature_dict={}\n",
    "    position=sense_eval_inst.position\n",
    "    context=sense_eval_inst.context\n",
    "    cur_word_tag=context[position]\n",
    "    prev_word_tag=context[position-1]\n",
    "    next_word,next_tag=\"\",\"\"\n",
    "    if position<len(context)-1:\n",
    "        next_word_tag=context[position+1]\n",
    "        if len(next_word_tag)==2: next_word,next_tag=next_word_tag\n",
    "    feature_dict[\"position\"]=position\n",
    "    feature_dict[\"prev_word\"]=prev_word_tag[0]\n",
    "    feature_dict[\"prev_tag\"]=prev_word_tag[1]\n",
    "    feature_dict[\"next_word\"]=next_word\n",
    "    feature_dict[\"next_tag\"]=next_tag\n",
    "\n",
    "    return feature_dict\n",
    "sense_features(train_set[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "train_feature_set=[(sense_features(item),item.senses[0]) for item in train_set]\n",
    "test_feature_set=[(sense_features(item),item.senses[0]) for item in test_set]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.9030023094688222\n"
     ]
    }
   ],
   "source": [
    "nb_classifier = nltk.NaiveBayesClassifier.train(train_feature_set)\n",
    "print(nltk.classify.accuracy(nb_classifier, test_feature_set))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.9053117782909931\n"
     ]
    }
   ],
   "source": [
    "dt_classifier = nltk.DecisionTreeClassifier.train(train_feature_set)\n",
    "print(nltk.classify.accuracy(dt_classifier, test_feature_set))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  ==> Training (100 iterations)\n",
      "\n",
      "      Iteration    Log Likelihood    Accuracy\n",
      "      ---------------------------------------\n",
      "             1          -1.09861        0.085\n",
      "             2          -0.25924        0.825\n",
      "             3          -0.22525        0.887\n",
      "             4          -0.20155        0.908\n",
      "             5          -0.18457        0.924\n",
      "             6          -0.17169        0.934\n",
      "             7          -0.16147        0.943\n",
      "             8          -0.15311        0.947\n",
      "             9          -0.14608        0.949\n",
      "            10          -0.14007        0.954\n",
      "            11          -0.13485        0.955\n",
      "            12          -0.13027        0.957\n",
      "            13          -0.12619        0.959\n",
      "            14          -0.12254        0.961\n",
      "            15          -0.11925        0.962\n",
      "            16          -0.11626        0.963\n",
      "            17          -0.11354        0.964\n",
      "            18          -0.11103        0.965\n",
      "            19          -0.10873        0.966\n",
      "            20          -0.10660        0.966\n",
      "            21          -0.10462        0.966\n",
      "            22          -0.10277        0.967\n",
      "            23          -0.10105        0.967\n",
      "            24          -0.09944        0.968\n",
      "            25          -0.09792        0.968\n",
      "            26          -0.09649        0.968\n",
      "            27          -0.09515        0.968\n",
      "            28          -0.09388        0.968\n",
      "            29          -0.09268        0.968\n",
      "            30          -0.09153        0.968\n",
      "            31          -0.09045        0.968\n",
      "            32          -0.08942        0.968\n",
      "            33          -0.08844        0.968\n",
      "            34          -0.08750        0.968\n",
      "            35          -0.08660        0.969\n",
      "            36          -0.08575        0.969\n",
      "            37          -0.08493        0.969\n",
      "            38          -0.08414        0.969\n",
      "            39          -0.08339        0.969\n",
      "            40          -0.08266        0.969\n",
      "            41          -0.08196        0.969\n",
      "            42          -0.08129        0.969\n",
      "            43          -0.08065        0.969\n",
      "            44          -0.08002        0.969\n",
      "            45          -0.07942        0.969\n",
      "            46          -0.07884        0.969\n",
      "            47          -0.07828        0.969\n",
      "            48          -0.07774        0.969\n",
      "            49          -0.07722        0.969\n",
      "            50          -0.07671        0.969\n",
      "            51          -0.07622        0.970\n",
      "            52          -0.07574        0.970\n",
      "            53          -0.07528        0.970\n",
      "            54          -0.07483        0.970\n",
      "            55          -0.07440        0.970\n",
      "            56          -0.07397        0.971\n",
      "            57          -0.07356        0.971\n",
      "            58          -0.07316        0.971\n",
      "            59          -0.07277        0.971\n",
      "            60          -0.07240        0.971\n",
      "            61          -0.07203        0.971\n",
      "            62          -0.07167        0.971\n",
      "            63          -0.07132        0.971\n",
      "            64          -0.07098        0.971\n",
      "            65          -0.07065        0.971\n",
      "            66          -0.07032        0.971\n",
      "            67          -0.07001        0.971\n",
      "            68          -0.06970        0.971\n",
      "            69          -0.06940        0.971\n",
      "            70          -0.06910        0.971\n",
      "            71          -0.06881        0.971\n",
      "            72          -0.06853        0.971\n",
      "            73          -0.06826        0.971\n",
      "            74          -0.06799        0.971\n",
      "            75          -0.06773        0.971\n",
      "            76          -0.06747        0.972\n",
      "            77          -0.06722        0.972\n",
      "            78          -0.06697        0.972\n",
      "            79          -0.06673        0.972\n",
      "            80          -0.06649        0.972\n",
      "            81          -0.06626        0.972\n",
      "            82          -0.06603        0.972\n",
      "            83          -0.06581        0.972\n",
      "            84          -0.06559        0.972\n",
      "            85          -0.06537        0.972\n",
      "            86          -0.06516        0.972\n",
      "            87          -0.06495        0.972\n",
      "            88          -0.06475        0.972\n",
      "            89          -0.06455        0.972\n",
      "            90          -0.06436        0.972\n",
      "            91          -0.06416        0.972\n",
      "            92          -0.06397        0.972\n",
      "            93          -0.06379        0.972\n",
      "            94          -0.06361        0.972\n",
      "            95          -0.06343        0.972\n",
      "            96          -0.06325        0.972\n",
      "            97          -0.06308        0.972\n",
      "            98          -0.06291        0.972\n",
      "            99          -0.06274        0.972\n",
      "         Final          -0.06257        0.972\n",
      "0.9214780600461894\n"
     ]
    }
   ],
   "source": [
    "me_classifier = nltk.MaxentClassifier.train(train_feature_set)\n",
    "print(nltk.classify.accuracy(me_classifier, test_feature_set))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.9214780600461894\n"
     ]
    }
   ],
   "source": [
    "print(nltk.classify.accuracy(me_classifier, test_feature_set))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[PPAttachment(sent='0', verb='join', noun1='board', prep='as', noun2='director', attachment='V'), PPAttachment(sent='1', verb='is', noun1='chairman', prep='of', noun2='N.V.', attachment='N'), ...]"
      ]
     },
     "execution_count": 96,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from nltk.corpus import ppattach\n",
    "ppattach.attachments('training')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "('chairman', 'of', 'N.V.')"
      ]
     },
     "execution_count": 97,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "inst = ppattach.attachments('training')[1]\n",
    "(inst.noun1, inst.prep, inst.noun2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "inst = ppattach.attachments('training')[2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "('director', 'of', 'conglomerate')"
      ]
     },
     "execution_count": 99,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "(inst.noun1, inst.prep, inst.noun2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "nattach = [inst for inst in ppattach.attachments('training') if inst.attachment == 'N']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "PPAttachment(sent='1', verb='is', noun1='chairman', prep='of', noun2='N.V.', attachment='N')"
      ]
     },
     "execution_count": 101,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nattach[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "PPAttachment(sent='280', verb='seek', noun1='seat', prep='in', noun2='Parliament', attachment='N')"
      ]
     },
     "execution_count": 102,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nattach[100]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'noun1': 'seat', 'noun2': 'Parliament'}"
      ]
     },
     "execution_count": 103,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def get_pp_att_features(pp_att_inst):\n",
    "    noun1=pp_att_inst.noun1\n",
    "    noun2=pp_att_inst.noun2\n",
    "    prep=pp_att_inst.prep\n",
    "    feature_dict={}\n",
    "    feature_dict[\"noun1\"]=noun1\n",
    "    feature_dict[\"noun2\"]=noun2    \n",
    "    return feature_dict\n",
    "\n",
    "get_pp_att_features(nattach[100])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "pp_training_set=ppattach.attachments('training')\n",
    "pp_test_set=ppattach.attachments('test')\n",
    "\n",
    "pp_train_feature_set=[(get_pp_att_features(item),item.prep) for item in pp_training_set]\n",
    "pp_test_feature_set=[(get_pp_att_features(item),item.prep) for item in pp_test_set]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "({'noun1': 'board', 'noun2': 'director'}, 'as')\n",
      "({'noun1': 'chairman', 'noun2': 'N.V.'}, 'of')\n",
      "({'noun1': 'director', 'noun2': 'conglomerate'}, 'of')\n",
      "({'noun1': 'percentage', 'noun2': 'deaths'}, 'of')\n",
      "({'noun1': 'crocidolite', 'noun2': 'filters'}, 'in')\n"
     ]
    }
   ],
   "source": [
    "for a in pp_train_feature_set[:5]:\n",
    "    print(a)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.4342912495963836\n"
     ]
    }
   ],
   "source": [
    "nb_classifier = nltk.NaiveBayesClassifier.train(pp_train_feature_set)\n",
    "print(nltk.classify.accuracy(nb_classifier, pp_test_feature_set))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'in'"
      ]
     },
     "execution_count": 110,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nb_classifier.classify({'noun1': 'researcher', 'noun2': 'Canada'})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'of'"
      ]
     },
     "execution_count": 111,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nb_classifier.classify({'noun1': 'team', 'noun2': 'researchers'})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  ==> Training (100 iterations)\n",
      "\n",
      "      Iteration    Log Likelihood    Accuracy\n",
      "      ---------------------------------------\n",
      "             1          -4.30407        0.003\n",
      "             2          -1.29282        0.799\n",
      "             3          -0.89499        0.838\n",
      "             4          -0.72269        0.850\n",
      "             5          -0.62480        0.859\n",
      "             6          -0.56096        0.864\n",
      "             7          -0.51566        0.869\n",
      "             8          -0.48163        0.872\n",
      "             9          -0.45499        0.874\n",
      "            10          -0.43348        0.876\n",
      "            11          -0.41568        0.878\n"
     ]
    }
   ],
   "source": [
    "me_classifier = nltk.MaxentClassifier.train(pp_train_feature_set)\n",
    "print(nltk.classify.accuracy(me_classifier, pp_test_feature_set))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
